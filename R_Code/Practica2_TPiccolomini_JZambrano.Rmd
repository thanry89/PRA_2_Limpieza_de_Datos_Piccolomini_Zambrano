---
title: "PRA 2 - Limpieza y Análisis de Datos"
author: Jonathan Zambrano / Tatiana Piccolomini
date: "Junio 2021"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

******
# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
******

El dataset seleccionado contiene datos sobre trabajos de Data scientist escrapeada de Glassdoor, recordemos que Glassdoor es un sitio web estadounidense donde los empleados actuales y anteriores revisan las empresas de forma anónima. Glassdoor también permite a los usuarios enviar y ver salarios de forma anónima, así como buscar y solicitar puestos de trabajo en su plataforma.


Una utilidad de este dataset es poder realizar un analisis de salario por sectores , ver las puntuaciones que los empleados ponen. Un buen analisis de este dataset de forma particular puede ayudar a definir el salario pretendido al comenzar a trabajar como Data Scientist, saber en que sectores se requiere este perfil profesional, que tipo de empresas y cuales de estas esta mejor puntuada. De tal manera, que el análisis que se realizará se enfoca en entender la tendencia respecto de los requerimientos del mercado actual; así como la búsqueda de la relación entre la información empresarial disponible y su remuneración.

  - Columnas Data Set Original:

"index"           "Job.Title"   "Salary.Estimate"   "Job.Description"       "Rating"            "Company.Name"      "Location"         

"Headquarters"    "Size"        "Founded"           "Type.of.ownership"     "Industry"          "Sector"            "Revenue"          

"Competitors"


  - Columnas del Data set limpio:

"Job.Title"       "Job.Type"    "Salary.Estimate"     "Salary.Mean"   "Rating"    "Company.Name"    "Location"    

"Headquarters"    "Size"        "Type.of.ownership"   "Industry"      "Sector"    "Revenue"         "Competitors"


  **Detalle de los atributos del dataset (672 observaciones):**


  - Job.Title: Título del trabajo. Ej: "Sr Data Scientist".

  - Salary.Estimate: Rango del valor del salario anual estimado (k USD). Ej: “$137K-$171K (Glassdoor est.).

  - Rating: Valoración que los usuarios de la página dieron al anuncio. Ej: 3.1.

  - Company.Name: Nombre de la empresa que posteo el anuncio. Ej: Healthfirst.

  - Location: Ubicación de la empresa. Ej: New York, NY.

  - Headquarters: Ubicación de la oficina central de la empresa. Ej: Boston, MA.

  - Size: Cantidad de empleados que conforman a la empresa. Ej: 1001 to 5000 employees.

  - Founded: Año de fundación de la empresa. Ej: 1993.

  - Type.of.ownership: Tipo de organización a la que corresponde la empresa. Ej: Nonprofit Organization.

  - Industry, Sector: Área de trabajo en la que se desempeñan las actividades de la empresa. Ej: Research & Development – Business Services.

  - Revenue: Ganancias totales anuales de la empresa. Ej: $1 to $2 billion (USD).

  - Competitors: Principales competidores. Ej: EmblemHealth, UnitedHealth Group, Aetna.


Fuente: https://www.kaggle.com/rashikrahmanpritom/data-science-job-posting-on-glassdoor

******
##  Lectura del fichero
******

A continuación, previo al desarrollo del dataset procederemos a realizar la lectura del fichero y la instalación de las librerias a utilizar:  

```{r,eval=TRUE,echo=TRUE}
# Instalación y llamado a las librerías a utilizar
if(!require(dplyr)){
install.packages('dplyr')
library(dplyr)
}

if(!require(stringr)){
install.packages('stringr')
library(stringr)
}

if(!require(VIM)){
install.packages('VIM')
library(VIM)
}

if(!require(ggplot2)){
install.packages('ggplot2')
library(ggplot2)
}

if(!require(car)){
install.packages('car')
library(car)
}

if(!require(kableExtra)){
install.packages('kableExtra')
library(kableExtra)
}
```

```{r,eval=TRUE,echo=TRUE}
# Lectura de archivo obtenido de la fuente de kaggle
data <- read.csv('Uncleaned_DS_jobs.csv')
```

Así mismo, para tener una visión general del dataset, se presente un resumen y extracto de los datos contenidos:

```{r,eval=TRUE,echo=TRUE}
# Presentación del resumen de los datos
summary(data)
# Presentación de un extracto y tipo de variables
str(data)
```

******
# Integración y selección de los datos de interés a analizar.
******

El presente dataset se encuentra completo, por lo cual, no será necesario realizar trabajos de integración de los datos, de igual manera, se considera que todos los atributos serán necesarios para el análisis, por lo que, posteriormente y en base a los resultados obtenidos se realizarán tareas de selección de datos según sea el caso. En este apartado se incluye la excepción de los atributos Index y Job Description, los cuales se considera que no poseen información relevante para el análisis propuesto; por lo cual, serán eliminados.

```{r,eval=TRUE,echo=TRUE}
#Eliminamos Index y descripcion
data <- data[,-c(1,4)]
```

******
# Limpieza de datos
******

En base a los datos revisamos y mostrados en el punto anterior, se presenta a continuación una serie de trabajos de limpieza de datos en base a cada uno de los atributos del dataset:

  - Job.Title: De la revisión realizada a los datos contenidos en este apartado, se verifica que existen diferentes nombres ingresados en función del trabajo solicitado. Así mismo, se evidencia que existen palabras clave dentro de los datos, de los cuales se han seleccionado los siguientes valores:
      -	Data Scientist.
      -	Data Analyst.
      -	Business Intelligence Analyst.
      -	Machine Learning.
      -	Data Engineer.
      -	Other (Cualquier otra descripción).
    De tal manera, que se creará un nuevo atributo cuantitativo correspondiente al tipo de anuncio.

```{r,eval=TRUE,echo=TRUE}
# Filtrado y creación del atributo Job.Type
data <- data %>%
  mutate(Job.Type = case_when(
    str_detect(Job.Title,"Data Scientist") ~ "Data Scientist",
    str_detect(Job.Title,"Data Analyst") ~ "Data Analyst",
    str_detect(Job.Title,"Business Intelligence Analyst") ~ "Business Intelligence Analyst",
    str_detect(Job.Title,"Machine Learning") ~ "Machine Learning Engineer",
    str_detect(Job.Title,"Data Engineer") ~ "Data Engineer",
  ))
# Se asigna el valor Other
data <- mutate_at(data, c("Job.Type"), ~ replace(., is.na(.), "Other"))
``` 

  - Salary.Estimate: Para este atributo se evidencia que existen caracteres adicionales sobre el valor del salario, por lo cual, se procederá a eliminarlos, para finalmente obtener el rango de valores.

```{r,eval=TRUE,echo=TRUE}
# Limpieza de la variable Salario
data$Salary.Estimate <- str_extract(data$Salary.Estimate,"[^(]+")
data$Salary.Estimate <- str_remove_all(data$Salary.Estimate,"\\$")
data$Salary.Estimate <- str_remove_all(data$Salary.Estimate,"\\K")   
``` 

  - Company.Name: En este apartado se verifica que al final de cada nombre se muestra el valor de su rating, por lo cual, se procede a eliminarlo.

```{r,eval=TRUE,echo=TRUE}
# Limpieza del atributo Nombre de la empresa
data$Company.Name <- str_extract(data$Company.Name,"[^\\n]+")
``` 

  - Size: Se evidencia que al final de la descripción del atributo se encuentra la palabra "employees", la cual, será eliminada.

```{r,eval=TRUE,echo=TRUE}
# Limpieza del atributo Size
data$Size <- str_remove(data$Size, "\\ employees")
```

  - Revenue: Ganancias totales anuales de la empresa. Ej: $1 to $2 billion (USD).
Sobre estos valores se han eliminado los caracteres correspondientes a la moneda, considerando que los valores se encuentran en USD Dolars.

```{r,eval=TRUE,echo=TRUE}
# Limpieza del atributo Revenue
data$Revenue <- str_remove_all(data$Revenue,"\\$")
data$Revenue <- str_remove(data$Revenue,fixed(" (USD)"))
```


```{r,eval=TRUE,echo=TRUE}
# Ordenamiento de los atributos
data <- data[,c(1,14,2,3,4,5,6,7,8,9,10,11,12,13)]
# Presentación de los datos limpios
str(data)
```

******
## ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?
******

Luego del análisis del dataset, se verifica que, si bien todos los campos presentan valores completos existen datos con un valor numérico de “-1”, el cual, se ha considerado como un valor o elemento vacío. Para lo cual, se reasignará el valor de estos datos como “NA”.

```{r,eval=TRUE,echo=TRUE}
# Asiganación de valor NA a valores -1
data[data == -1] <- NA
```

De igual manera, se encuentra que existen valores denominados como desconocidos (“Unknown”) que no se consideran elementos vacíos, sino como la denominación de valores no conocidos dentro de cada atributo.

Para la gestión de los valores o elementos vacíos se presenta una estadística de la cantidad de valores vacíos presentes en cada grupo de datos:

```{r,eval=TRUE,echo=TRUE}
#Busqueda de NAs
print('Cantidad de NA s')
apply(is.na(data), 2, sum)
```

En primer lugar, se gestionarán los datos vacíos del atributo Rating, en el cual, considerando que se trata de una variable cualitativa, se utilizará el algoritmo de k-vecinos mas cercanos (k-NN) para aproximar el valor de los datos faltantes, en donde, tenemos lo siguiente:

```{r,eval=TRUE,echo=TRUE}
# Reemplazo de NAs numéricos
data$Rating <- kNN(data)$Rating
```

Como siguiente paso en la gestión de los elementos vacíos, luego de una inspección a los registros del dataset, se evidencia que existen registros que no cuentan con información completa de la empresa solicitante, donde, los únicos datos disponibles corresponden al del nombre y ubicación de la empresa; por lo que se considera que estos registros (27) no cuentan con información fiable. De tal manera, que procederemos a identificar y posteriormente eliminar estos registros.

Así se muestra un extracto de los datos que se pretende eliminar:

```{r,eval=TRUE,echo=TRUE}
# Identificación de filas sin información de compañia
missing <- data[rowSums(is.na(data[ , 8:11])) == 4, ]
# Presentación de un extracto de las filas a eliminar
head(missing)
```

Posteriormente se eliminan los datos indicados:

```{r,eval=TRUE,echo=TRUE}
# Eliminación de filas sin información de compañia
index <- which(rowSums(is.na(data[ , 8:11])) == 4)
data <- data[-index,]
```

Finalmente, se verifica que el resto de los datos faltantes se encuentran en los campos de Headcuarters, Founded, Industry, Sector y Competitors, los cuales, no pueden ser aproximados o establecidos debido a que corresponden a datos específicos de cada empresa, por lo cual, el tratamiento que daremos a estos datos será el de asignarles la etiqueta de “Unknown”. Así mismo, es importante recalcar que el atributo Competitors presenta un 73% de valores pérdidos, por lo que posteriormente, este atributo no será considerado para el análisis.

```{r,eval=TRUE,echo=TRUE}
# Cambio de NAs a Unknown
data <- mutate_at(data, c(7,9,11,12,14),~ replace(., is.na(.), "Unknown"))
```

Así ya contamos con un dataset son valores vacíos como se muestra a continuación:

```{r,eval=TRUE,echo=TRUE}
#Busqueda de NAs
print('Cantidad de NA s')
apply(is.na(data), 2, sum)
```

Considerando que los valores de salario se presentan en un atributo categórico, se procede a generar un nuevo atributo que permita obtener un valor estimado/promedio del salario percibido por cada trabajo, para lo cual, calculará el valor promedio de salario en base al rango categórico presentado:

```{r,eval=TRUE,echo=TRUE}
# Calculo de Salario Promedio, ya que salario toma valores por rango.
data <- data %>% rowwise() %>%
  mutate(Salary.Mean = mean(c(as.numeric(strsplit(Salary.Estimate,"\\-")[[1]][1]),
                           as.numeric(strsplit(Salary.Estimate,"\\-")[[1]][2]))))
# Deagrupación de datos usada en el paso previo
data <- ungroup(data)
```

******
## Identificación y tratamiento de valores extremos.
******

Para la identificación de los valores extremos o outliners utilizaremos la representación del gráfico de cajas (boxplots) con el objetivo de detectar aquellos valores que se encuentran mas alla de 3 desviaciones estándar de la media. Para nuestro caso, se evaluarán los outliners para los atributos de Salary.Mean y Rating.

  - Valores Extremos en Salary.Mean

Para el análisis de valores extremos se presentará en primer lugar la gráfica de boxplot, y posteriormente evaluaremos los valores que se encuentra alejados tanto por arriba como por abajo. 

```{r,eval=TRUE,echo=TRUE}
# Evaluación del Diagrama de Cajas de Salary.Mean
boxplot(data$Salary.Mean) -> out_salary
```

```{r,eval=TRUE,echo=TRUE}
# Obtención de los valores extremos
unique(out_salary$out)
```

Del diagrama de cajas encontrado se obtienen que existen dos valores (mínimo y máximo) en salarios ofertados para Data Science. Para determinar si se pueden considerar como valores extremos se evaluará si existe alguna empresa que se encuentra ofertando salarios por fuera de la media, por lo cual, se presenta el listado de empresas que presentan un salario mínimo y máximo.

```{r,eval=TRUE,echo=TRUE}
# Listado de Empresas que ofertan el salario mínimo
print("Empresas que ofertan salario mínimo:")
data$Company.Name[data$Salary.Mean == 43.5]
```

```{r,eval=TRUE,echo=TRUE}
# Listado de Empresas que ofertan el salario máximo
print("Empresas que ofertan salario máximo:")
data$Company.Name[data$Salary.Mean == 271.5]
```

De la evaluación realizada al listado de empresas se puede concluir que los valores encontrados no pueden considerarse extremos; así como se determina que no se encuentra una tendencia respecto a Job.Type o Revenue que indique el tipo de empresa o empleo que represente un salario máximo o mínino; por lo que, se puede concluir que en el mercado laboral los salarios correspondientes a Data Science se encuentran distribuidos uniformemente.   

  - Valores Extremos en Rating

Así mismo para el análisis de valores extremos se presentará la gráfica de boxplot, y los valores detectados. 

```{r,eval=TRUE,echo=TRUE}
# Evaluación del Diagrama de Cajas de Rating
boxplot(data$Rating) -> out_rating
unique(out_rating$out)
```

En este caso, se obtuvo que se presentan valores extremos por debajo de la media, por lo cual, se analizará si existen empresas que presenten un rating menor a 2.5, valor límite de las 3 desviaciones estándar de la muestra.

```{r,eval=TRUE,echo=TRUE}
# Listado de Empresas que presentan menor Rating
print("Empresas que presentan menor Rating:")
data$Company.Name[data$Rating < 2.5]
```

En este caso, al existir algunas empresas por debajo de este umbral no se considera como un valor extremo, si no mas bien una representación de las empresas que, según el criterio de los usuarios, ofertan puestos no atractivos en el campo de Data Science.


Una vez que contamos con el dataset limpio, solo resta realizar la redefinición de las variables correspondientes al tipo factor.

```{r,eval=TRUE,echo=TRUE}
# Cambio a Factor las variables categoricas.
data$Salary.Estimate = factor(data$Salary.Estimate)
data$Size = factor(data$Size)
data$Type.of.ownership = factor(data$Type.of.ownership)
data$Sector = factor(data$Sector)
data$Revenue = factor(data$Revenue)
data$Job.Type = factor(data$Job.Type)
```

Así, para culminar la etapa de limpieza de datos, se presenta el resumen y extracto de los datos limpios.

```{r,eval=TRUE,echo=TRUE}
# Ordenamiento de los atributos
data <- data[,c(1,2,3,15, 4,5,6,7,8,9,10,11,12,13,14)]
# Presentación del resumen de los datos
summary(data)
# Presentación de un extracto y tipo de variables
str(data)
```

Se guarda el dataset limpio.

```{r,eval=TRUE,echo=TRUE}
# Escritura del Fichero
write.csv(data,"Cleaned_DS_jobs.csv")
```

A continuacion realizaremos las consignas  4, 5 y 6 del la PRA2:

  4. Análisis de los datos. 
  
  5. Representación de los resultados a partir de tablas y gráficas.

  6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema? 

******
# Análisis de los datos
******

******
## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)
******

Para continuar con el análisis consiguiente se ha determinado el uso de las siguientes variables, considerando que las variables no seleccionadas no tienen inflencia en las respuestas a las preguntas planteadas.

Variables a utilizar:

  - Job.Type (factor)
  - Salary.Mean (numeric)
  - Rating (numeric)
  - Size (factor)
  - Type.of.Ownership (factor)
  - Sector (factor)
  - Revenue (factor)

**Preguntas:**

  - Hay diferencia por sector en relacion al salario?, se realizara un analisis bivariado de las variables Salary.Mean y Sector.

  - Que tipo de empresa tiene mejor Rating?, se realizara un analisis bivariado de las variables Rating y Type.of.ownership.


******
## Comprobación de normalidad y homogeneidad de la varianza 
******

En este apartado se aplicarán las siguientes pruebas:

  - Test de normalidad de Shapiro para las variables Salary.Mean y Rating:

```{r,eval=TRUE,echo=TRUE}
# Se aplica el test de normalidad de Shapiro para las variables Salary.Mean y Rating 
shapiro.test(data$Salary.Mean)
shapiro.test(data$Rating)
```

En el test de Shapiro-Wilks se plantea como hipótesis nula que una muestra x1, ..., xn proviene de una población normalmente distribuida.

Interpretación del test de Shapiro: Siendo la hipótesis nula que la población está distribuida normalmente, si el p-valor es menor a alfa (nivel de significancia) entonces la hipótesis nula es rechazada (se concluye que los datos no vienen de una distribución normal). Si el p-valor es mayor a alfa, se concluye que no se puede rechazar dicha hipótesis.
 
De tal manera, que debido a que los test de Normalidad de Shapiro-Wilks dieron p-valores muy pequeños para las variables Rating y Salary.Mean, no podemos decir que tienen una distribucion normal.


Los siguientes correspoden a tests no paramétricos que comparan las varianzas basándose en la mediana. Es también una alternativa cuando no se cumple la condición de normalidad en las muestras.

  - Test de Levene para la variable Rating agrupado por Size, para ver si la varianza es similar o no en cada grupo:

```{r,eval=TRUE,echo=TRUE}
# Se aplica el test de Levene de homogeneidad de la varianza de Rating agrupado por Size 
leveneTest(Rating ~ Size, data = data)
```

El test de Levene presenta un resultado significativo

  - Test de Fligner de diferencia de varianza para Salary.Mean por Rating:

```{r,eval=TRUE,echo=TRUE}
# Se aplica el test de homogeneidad de la varianza para las variables Salary.Mean y Rating 
fligner.test(Salary.Mean ~ Rating, data = data)
```

El resultado del test de Fligner para homegeneidad de la varianza de Salary.Mean vs Rating no fue significativa.

******
## Aplicación de pruebas estadísticas para comparar los grupos de datos
******

  - Correlacion entre las variables Rating y Salary.Mean. 

```{r,eval=TRUE,echo=TRUE}
# Correlación entre variables Salary.Mean y Rating
cor.test(data$Salary.Mean, data$Rating, method = "spearman", exact = FALSE)
```

En base a la valor de rho obtenido se podría pensar que el Rating no estaría linealmente correlacionado con el Salario.


  - Test de Chi cuadrado para ver independencia de  Salary.Mean con las variables Rating , Size , Sector , Job.Type , Revenue , Type.of.ownership 

```{r,eval=TRUE,echo=TRUE}
# Test Chi Cuadrado (Job.Type vs Salary Mean) 
Job.Type <- table(data$Job.Type, data$Salary.Mean)
chisq.test(Job.Type)

# Test Chi Cuadrado (Rating vs Salary Mean) 
Rating <- table(data$Rating, data$Salary.Mean)
chisq.test(Rating)

# Test Chi Cuadrado (Size vs Salary Mean)
Size <- table(data$Size, data$Salary.Mean)
chisq.test(Size)

# Test Chi Cuadrado (Sector vs Salary Mean)
Sector<- table(data$Sector, data$Salary.Mean)
chisq.test(Sector)

# Test Chi Cuadrado (Revenue vs Salary Mean)
Revenue <- table(data$Revenue, data$Salary.Mean)
chisq.test(Revenue)

# Test Chi Cuadrado (Ownership vs Salary Mean)
own <- table(data$Type.of.ownership, data$Salary.Mean)
chisq.test(own)
```

Mirando los resultados la unica variable en donde se rechaza la hipotesis nula es Job.Type frente a Salary.Mean, por lo que se puede concluir que existe una asociación significativa entre el tipo de trabajo y su salario.

  - Regresion lineal con variable objetivo (target) Salary.Mean y variables independientes  Rating, Size, Sector, Job.Type, Revenue y Type.of.ownership.

```{r,eval=TRUE,echo=TRUE}
# Regresión lineal
m1 = lm(Salary.Mean ~ Rating + Size + Sector + Job.Type + Revenue + Type.of.ownership, data = data)
summary(m1)
```

Solo se entreno una regresion lineal con los datos. Se hizo con un fin de relacion lineal entre variables y no como entrenamiento de un modelo de Machine learning que sirva para predecir el Salary.Mean, pues este otro objetivo requeriria otra metodologia.
 
El R cuadrado obtenido es bajo. Lo cual era esperable porque pareciera no haber relacion nivel aparente entre la variable objetivo y las regresoras.


  - Análisis Comparativo de Valores Promedio de Salary y Rating por atributo

En este apartado se pretende evaluar a través de la comparativa de los atributos Salary.Mean y Rating y el resto de atributos, cuales son los campos que tienen los mejores salarios y ratings, con el objetivo de obtener una idea mas global de las áreas que lideran el mercado laboral en Data Science.

```{r,eval=TRUE,echo=TRUE}
# Creación de la función para cálculo de valores promedio
promedios <- function(x) mean(x, na.rm = TRUE)
# Generación de dataframe con valores máximos promedios de Salary.Mean
out_Salary <- data.frame(var=c("Size","Ownership","Sector","Revenue"),
                  Col_Max = c(names(which.max(tapply(data$Salary.Mean, data$Size, promedios))),
                              names(which.max(tapply(data$Salary.Mean, data$Type.of.ownership, promedios))),
                              names(which.max(tapply(data$Salary.Mean, data$Sector, promedios))),
                              names(which.max(tapply(data$Salary.Mean, data$Revenue, promedios)))),
                  Salary_Mean_Max = c(max(tapply(data$Salary.Mean, data$Size, promedios)),
                                      max(tapply(data$Salary.Mean, data$Type.of.ownership, promedios)),
                                      max(tapply(data$Salary.Mean, data$Sector, promedios)),
                                      max(tapply(data$Salary.Mean, data$Revenue, promedios))))
# Creación de la tabla
out_Salary %>% kable() %>% kable_styling()
```

Así, en base al promedio de Salary se puede obtener que el Sector de Servicio al Cliente es el área que mejor paga dentro del Data Science y así mismo, aunque en menor cantidad se puede ver que la empresas Hospitalarias también ofrecen un nivel de salario alto. 

Otro punto a resaltar en la tabla previa, es que el área del Data Science presenta un nivel de ingreso alto (aproximadamente 12000 (USD/mes)). 

De igual manera, procedemos con el mismo análisis ahora respecto del rating de los anuncios:

```{r,eval=TRUE,echo=TRUE}
# Generación de dataframe con valores máximos promedios de Rating
out_Rating <- data.frame(var=c("Size","Ownership","Sector","Revenue"),
                  Col_Max = c(names(which.max(tapply(data$Rating, data$Size, promedios))),
                              names(which.max(tapply(data$Rating, data$Type.of.ownership, promedios))),
                              names(which.max(tapply(data$Rating, data$Sector, promedios))),
                              names(which.max(tapply(data$Rating, data$Revenue, promedios)))),
                  Rating_Mean_Max = c(max(tapply(data$Rating, data$Size, promedios)),
                                      max(tapply(data$Rating, data$Type.of.ownership, promedios)),
                                      max(tapply(data$Rating, data$Sector, promedios)),
                                      max(tapply(data$Rating, data$Revenue, promedios))))
# Creación de la tabla
out_Rating %>% kable() %>% kable_styling()
```

En esta comparativa se puede observar que los valores de rating en cada uno de los atributos presentan valores altos (mayor a 4), en donde, es llamativo observar que es las organizaciones que tienen bajo número de empleados son la que mejor rating tiene, pudiendo llevar a concluir que las empresas más pequeñás son las que se preocupan mayormente en el ambiente laboral. Así mismo 

******
# Representación de los resultados a partir de tablas y gráficas.
******

- Graficos univariados

Comenzamos observando graficos univariados de las variables a analizar, en donde, se observará que cantidad de veces toman cada valor cada una de las variables categoricas.


  - GRafico de Barras de variables categoricas:

    -   "Job.Type",  "Location",   "Size",     "Type.of.ownership",  "Sector".


```{r,eval=TRUE,echo=TRUE}
# Gráfico univariado de Job.Type
plot(data$Job.Type, main='Job Type')
```

```{r,eval=TRUE,echo=TRUE}
# Gráfico univariado de Sector
plot(data$Sector, main='Sector')
```


```{r,eval=TRUE,echo=TRUE}
# Gráfico univariado de OwnerShip
plot(data$Type.of.ownership, main='Type.of.ownership')
```

```{r,eval=TRUE,echo=TRUE}
# Gráfico univariado de Size
plot(data$Size, main='Size')
```

```{r,eval=TRUE,echo=TRUE}
# Gráfico univariado de Revenue
plot(data$Revenue, main='Revenue')
```

  - Grafico densidad de las variables  Salary y Rating

Se presenta a continuación un histograma para identificar las frecuencias de los datos respecto de Salario y Rating de las ofertas.

```{r,eval=TRUE,echo=TRUE}
# Histograma de Salario
hist(data$Salary.Mean, col = "steelblue", breaks=10)
# Histograma de Rating
hist(data$Rating, col = "green")

```

  - Graficos de densidad y test de Levene para las variables Salary.Mean y Sector

El test de normalidad de la variable Salary.Mean dio negativo mas arriba.

```{r,eval=TRUE,echo=TRUE}
leveneTest(Salary.Mean ~ Sector, data = data)
print('Distribucion de Salary.Mean eparado por sector')
p2 <- ggplot(data=data, aes(x=Salary.Mean, group=Sector, fill=Sector)) +
    geom_density(adjust=1.5, alpha=.4) 
p2
```

Vemos que la distribucion de Salary.Mean cambia su distribucon segun cada sector.
Como el p-valor del test de levene es aprox. 0,4  las varianzas del Salario parecieran no ser diferentes segun el sector en el que nos encontremos (se acepto la hipotesis nula).

Obs: El test de Levene se puede aplicar con la función leveneTest() del paquete car. Se caracteriza, además de por poder comparar 2 o más poblaciones, por permitir elegir entre diferentes estadísticos de centralidad :mediana (por defecto), media, media truncada. Esto es importante a la hora de contrastar la homocedasticidad dependiendo de si los grupos se distribuyen de forma normal o no.


  - Graficos de densidad y test de Levene para las variables Rating y Type.of.ownership

```{r,eval=TRUE,echo=TRUE}

leveneTest(Rating ~ Type.of.ownership, data = data)
print('Distribucion de Rating separado por Type.of.ownership')
p3 <- ggplot(data=data, aes(x=Rating, group=Type.of.ownership, fill=Type.of.ownership)) +
    geom_density(adjust=1.5, alpha=.4) 
p3
```

Pareciera que la distribucion de Rating se diferencia en Goverment y Private practice. Y el test de Levene esta indicando que hay diferencia significativas de las varianzas del Rating en los distintos Type of ownership de las compañias empleadoras ya que el p-valor del test de Levene dio muy pequeño.

******
# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?
******

En el anális realizado previamente se ha considerado principalmente los atributos de Salary y Rating, tomando estos atributos como un medidor de calidad de las ofertas laborales, en donde se han obtenido las siguientes conclusiones:

  - Mediante el analísis de los valores extremos tomados por las variables Salary y Rating, se obtiene que ambos atributos presentan valores distribuidos en todas los atributos analizados, de tal manera, que no se puede establecer un Sector o tipo de empresa que presente un mejor/peor salario o una mejor/peor calificación.	

  - En base a las pruebas estadísticas realizadas se obtuvo que las variables Salary y Rating no siguen una distribución normal y adicionalmente no presentan una correlación lineal.

  - Al evaluar la relación entre el salario y el resto de atributos se puede concluir en base a la prueba estadística chi cuadrado que el salario tiene una asociación estadistica únicamente con el tipo de trabajo que en el caso de nuestra muestra tiene una frecuencia mas alta respecto a trabajos generales de Ciencia de Datos.
	
  - Respecto del salario se pudo observar que el sector que mejor retribuye es el de Servicio al Cliente, aunque de manera general se puede concluir que los salarios en el área de Ciencia de Datos presentan un valor alto.

  - Así mismo respecto del tipo de empresa y el Rating se pudo observar que en base a los datos recolectados el mejor Rating se presentaba entre los datos de los cuales no se dispone información del tipo de empresa, siendo las empresas Hospitalarias el siguente grupo mejor calificado.

  - De manera gráfica se pudo concluir que la densidad del salario varía según cada sector, aunque de igual forma se observa que las varianzas no presentan una mayor diferencia entre los sectores.

  - Con respecto a la densidad entre el tipo de empresa y su rating se observó una diferencia marcada entre los tipos de empresa relacionados al Gobierno y la empresa privada.

******
# Código
******

El presente proyecto de limpieza y análisis de datos se encuentra disponible en el siguiente portal de github:

https://github.com/thanry89/PRA_2_Limpieza_de_Datos_Piccolomini_Zambrano

